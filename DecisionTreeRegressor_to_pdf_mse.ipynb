{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#%matplotlib notebook\n",
    "#import seaborn as sns\n",
    "\n",
    "df_ALL = pd.read_sas(\"./HN16_ALL.sas7bdat\", format = 'sas7bdat', encoding='iso-8859-1')\n",
    "df_ffq = pd.read_sas(\"./hn16_ffq.sas7bdat\", format = 'sas7bdat', encoding='iso-8859-1')\n",
    "\n",
    "# 칼럼 저장\n",
    "# df_ffq.to_csv(\"df_ffq.csv\", encoding='iso-8859-1')\n",
    "# df_data.to_csv(\"df_data.csv\", encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비\n",
    "1. 2개의 데이터프레임에서 중복된 칼럼 확인\n",
    "2. 2번째 데이터프레임에서 키값으로 사용할 ID를 제외한 나머지 중복 칼럼을 삭제\n",
    "3. ID를 키값으로 2개의 데이터 프레임 머지(left, right, inner, outer, index 등 세팅 확인\n",
    "4. 정상적으로 데이터프레임 합쳐졌는지, 널값으로 확인\n",
    "5. 이후 decision tree sklearn regressor를 이용해서 확인(코딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개의 리스트에 각각의 데이터프레임의 컬럼명을 저장\n",
    "list_col_all = df_ALL.columns.values\n",
    "list_col_ffq = df_ffq.columns.values\n",
    "\n",
    "# 리스트를 집합으로 변환하여 intersection 사용하여 교집합 구하고 다시 리스트로 반환\n",
    "list_col_overlab = list(set(list_col_all).intersection(list_col_ffq))\n",
    "# print(len(list_col_overlab)) # 갯수 확인\n",
    "# list_col_overlab # 컬럼 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 26개의 중복 칼럼명 리스트에서 merge 시 key값으로 사용할 'ID'' 삭제\n",
    "list_col_overlab.remove('ID')\n",
    "# print(len(list_col_overlab)) # 갯수 확인\n",
    "# list_col_overlab # 컬럼 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8150, 434)\n",
      "(8150, 409)\n"
     ]
    }
   ],
   "source": [
    "# df_ffq 데이터프레임에서 ID를 제외한 나머지 중복 컬럼 삭제\n",
    "print(df_ffq.shape)\n",
    "df_ffq.drop(list_col_overlab, axis=1, inplace=True)\n",
    "print(df_ffq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8150, 1176)\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 merge\n",
    "df_merge = pd.merge(df_ALL, df_ffq, how='inner', on=[\n",
    "                                  'ID' # 개인 아이디\n",
    "                                  \n",
    "                                 ])\n",
    "print(df_merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 데이터프레임 확인\n",
    "# df_merge.to_csv(\"df_merge.csv\", encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4727, 1176)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 19세 이상으로만 제한\n",
    "df_data = df_merge.loc[(18 < df_merge.age), :]\n",
    "\n",
    "# 혈압치료중인 대상 제외\n",
    "df_data = df_data.loc[(1 < df_data.DI1_pt) | (df_data.DI1_pt < 1), :]\n",
    "\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null값 컬럼별 카운트 확인\n",
    "#df_nan_sort = df_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null값 많은 컬럼 및 카운트 저장\n",
    "#df_nan_sort.to_csv(\"df_nan_sort.csv\", encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4727, 1122)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 값이 null값이 컬럼 삭제\n",
    "df_data = df_data.dropna(axis=1, how='all')\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d233d4da9acf4a5697c57dba229d92c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def data_clean(input_list, is_cap=False) :\n",
    "    tmp_list = []\n",
    "    for d in input_list :\n",
    "        try :\n",
    "            float(d)\n",
    "            if is_cap :\n",
    "                tmp_list.append([d])\n",
    "            else :\n",
    "                tmp_list.append(d)\n",
    "        except :\n",
    "            if is_cap :\n",
    "                tmp_list.append([-1])\n",
    "            else :\n",
    "                tmp_list.append(-1)\n",
    "    return tmp_list\n",
    "\n",
    "def saveDTR(input_df, x_name, y_name) :\n",
    "    arrX1 = data_clean(getattr(input_df,x_name).fillna(-1), is_cap=True)\n",
    "    arrY = data_clean(getattr(input_df,y_name).fillna(-1))\n",
    "    \n",
    "    model = DecisionTreeRegressor(\n",
    "        criterion = 'mse',\n",
    "        max_depth=2\n",
    "    )\n",
    "    model.fit(arrX1,arrY)\n",
    "\n",
    "    dot_data = tree.export_graphviz(model,out_file=None,feature_names=[x_name], class_names=[y_name])\n",
    "\n",
    "    graph = graphviz.Source(dot_data) \n",
    "    graph.render(\"%s+%s\" % (x_name,y_name))\n",
    "\n",
    "    # mse값 계산. 정상적으로 만든건지는 모르겠음..\n",
    "    modelPrediction = model.predict(arrX1)\n",
    "    mse = mean_squared_error(arrY,modelPrediction)\n",
    "    # x_name, y_name, mse값을 mse_list에 append\n",
    "    mse_list.append([x_name, y_name, mse])\n",
    "    \n",
    "skip_list = [\n",
    "    df_data.HE_dbp.name\n",
    "    , df_data.HE_sbp.name\n",
    "]\n",
    "\n",
    "# saveDTR(df_data, df_data.age.name, df_data.HE_dbp.name)\n",
    "# saveDTR(df_data, df_data.age.name, df_data.HE_sbp.name)\n",
    "\n",
    "# mse list 담을 변수 준비\n",
    "mse_list = []\n",
    "\n",
    "for x_name in tqdm_notebook(df_data.columns):\n",
    "    if x_name in skip_list : continue\n",
    "    saveDTR(df_data, x_name, df_data.HE_dbp.name)\n",
    "    saveDTR(df_data, x_name, df_data.HE_sbp.name)\n",
    "\n",
    "# mse_list > dataframe으로 변환해서 csv파일로 저장   \n",
    "df_mse = pd.DataFrame(mse_list)\n",
    "df_mse.to_csv(\"mse_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
